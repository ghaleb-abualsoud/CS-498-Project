"""
Train and save the XGBoost model for heart disease prediction
"""
import numpy as np
import pandas as pd
import pickle
from pathlib import Path

from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
)

def train_model():
    print("Loading data...")
    # Load data
    df = pd.read_csv("heart_disease.csv")
    
    # Drop obvious id column if present
    if "id" in df.columns:
        df = df.drop(columns=["id"])
    
    # Simple numeric imputation
    df = df.fillna(df.median(numeric_only=True))
    
    # Predict thal from the rest, excluding cp
    X = df.drop(columns=["thal", "cp"])
    y = df["thal"]
    
    print("Running 10-fold cross-validation...")
    # 10-fold CV
    X_np = X.to_numpy()
    y_np = y.to_numpy()
    
    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
    
    accs, precs, recs, f1s, aucs = [], [], [], [], []
    
    for train_idx, test_idx in skf.split(X_np, y_np):
        X_train, X_test = X_np[train_idx], X_np[test_idx]
        y_train, y_test = y_np[train_idx], y_np[test_idx]
        
        model_cv = XGBClassifier(
            n_estimators=200,
            max_depth=4,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            objective="binary:logistic",
            eval_metric="logloss",
            random_state=42,
        )
        
        model_cv.fit(X_train, y_train)
        
        y_pred = model_cv.predict(X_test)
        y_proba = model_cv.predict_proba(X_test)[:, 1]
        
        accs.append(accuracy_score(y_test, y_pred))
        precs.append(precision_score(y_test, y_pred, zero_division=0))
        recs.append(recall_score(y_test, y_pred, zero_division=0))
        f1s.append(f1_score(y_test, y_pred, zero_division=0))
        aucs.append(roc_auc_score(y_test, y_proba))
    
    print("\n10-fold CV results:")
    print(f"Accuracy : {np.mean(accs):.3f} ± {np.std(accs):.3f}")
    print(f"Precision: {np.mean(precs):.3f} ± {np.std(precs):.3f}")
    print(f"Recall   : {np.mean(recs):.3f} ± {np.std(recs):.3f}")
    print(f"F1 score : {np.mean(f1s):.3f} ± {np.std(f1s):.3f}")
    print(f"ROC AUC  : {np.mean(aucs):.3f} ± {np.std(aucs):.3f}")
    
    print("\nTraining final model on full dataset...")
    # Fit final model on full data
    model = XGBClassifier(
        n_estimators=200,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        eval_metric="logloss",
        random_state=42,
    )
    model.fit(X, y)
    
    # Save model
    model_path = Path(__file__).parent / "model.pkl"
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    
    print(f"\nModel saved to {model_path}")
    print("\nFeature names:", list(X.columns))
    print("Feature importances:")
    for feature, importance in zip(X.columns, model.feature_importances_):
        print(f"  {feature}: {importance:.4f}")
    
    return model

if __name__ == "__main__":
    train_model()
